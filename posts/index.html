<!doctype html><html><head><title>Posts</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css><meta property="og:title" content="Posts"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://ericwang007.github.io/posts/"><meta property="og:updated_time" content="2021-10-27T06:00:20+06:00"><link rel=stylesheet href=/css/layouts/list.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/>EricWang's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"></ul></div></div></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts data-filter=all>Posts</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/posts/algorithmdatastructure/>Algorithm&DataStructure</a><ul><li><a href=/posts/algorithmdatastructure/%E6%8E%92%E5%BA%8F%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/ title=排序方法总结>排序方法总结</a></li><li><a href=/posts/algorithmdatastructure/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91/ title=最小生成树>最小生成树</a></li><li><a href=/posts/algorithmdatastructure/%E7%BA%A2%E9%BB%91%E6%A0%91/ title=红黑树>红黑树</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/bigdata/>BigData</a><ul><li><a href=/posts/bigdata/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%84%E4%BB%B6/ title=大数据组件>大数据组件</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/database/>Database</a><ul><li><a href=/posts/database/1-introduction/ title="1 Introduction">1 Introduction</a></li><li><a href=/posts/database/2-relation-database/ title="Relation Database">Relation Database</a></li><li><a href=/posts/database/3-sql/ title=SQL>SQL</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/java/>Java</a><ul><li><a href=/posts/java/java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/ title=Java基础语法>Java基础语法</a></li><li><a href=/posts/java/java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/ title=Java集合框架>Java集合框架</a></li><li><a href=/posts/java/java%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98/ title=Java面试问题>Java面试问题</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/linux/>Linux</a><ul><li><a href=/posts/linux/part-1/ title="Part 1">Part 1</a></li><li><a href=/posts/linux/part-2/ title="Part 2">Part 2</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/ml/>ML</a><ul><li><a href=/posts/ml/andrewng-cv%E5%9F%BA%E7%A1%80/ title=AndrewNG-CV基础>AndrewNG-CV基础</a></li><li><a href=/posts/ml/andrewng-dl%E5%9F%BA%E7%A1%80/ title=AndrewNG-DL基础>AndrewNG-DL基础</a></li><li><a href=/posts/ml/andrewng-dl%E5%BA%94%E7%94%A8/ title=AndrewNG-DL应用>AndrewNG-DL应用</a></li><li><a href=/posts/ml/andrewng-gan%E5%9F%BA%E7%A1%80/ title=AndrewNG-GAN基础>AndrewNG-GAN基础</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-1/ title=李宏毅-机器学习2021春-1>李宏毅-机器学习2021春-1</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-2/ title=李宏毅-机器学习2021春-2>李宏毅-机器学习2021春-2</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-3/ title=李宏毅-机器学习2021春-3>李宏毅-机器学习2021春-3</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-4/ title=李宏毅-机器学习2021春-4>李宏毅-机器学习2021春-4</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-5/ title=李宏毅-机器学习2021春-5>李宏毅-机器学习2021春-5</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-6/ title=李宏毅-机器学习2021春-6>李宏毅-机器学习2021春-6</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/os/>OS</a><ul><li><a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-1/ title="知识梳理 1">知识梳理 1</a></li><li><a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-2/ title="知识梳理 2">知识梳理 2</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/sdn/>SDN</a><ul><li><a href=/posts/sdn/sdn-1/ title="SDN 1">SDN 1</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid post-card-holder" id=post-card-holder><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-6/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-6</h5><p class="card-text post-summary">李宏毅-机器学习2021春-6 1 GNN 2 Deeep Reinforcement Learning (RL) 当人类也不知道什么是好的输出结果时，可以用RL。
2.1 RL与机器学习的关系 Step 1 Function with unknown parameters
用sample产生随机输出 Step 2 Define &ldquo;Loss&rdquo;
Step 3 Optimization
2.2 Policy Gradient 加入$A_n$，代表期望执行的程度。
$\gamma$：learning rate Policy Gradient的步骤：
On-policy & Off-policy
On-policy：用于训练的actor和用于交互的actor相同。 Off-policy：用于训练的actor和用于交互的actor不同。如Proximal Policy Optimization (PPO)。 2.3 Actor-Critic Montre-Carlo (MC) based approach Temporal-difference (TD) approach Veresion 3.5
Version 4 —— Advantage Actor-Critic</p></div><div class=card-footer><span class=float-left>October 27, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-6/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-2/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-2</h5><p class="card-text post-summary">李宏毅-机器学习2021春-2 1 机器学习任务攻略 Model bias：模型过于简单，有局限性
Optimization Issue：模型足够复杂了，但Optimization做的不够好。
Overfitting：在训练集上效果好，在测试集上效果差。解决方法如下：
增加训练数据，Data augmentation（图片左右翻转） 限制模型，减少模型的flexibility： 减少参数，共享参数（CNN） 减少features Early stopping Regularization Dropout 模型的复杂性需要在Overfitting和Model bias间进行trade-off
mismatch：训练集和测试集的数据分别不同
N-fold Cross Validation：将Training Set进行不同的分组，分别对模型进行训练和验证，得到的mse取平均值。
2 类神经网络训练不起来怎么办 2.1 Local Minima与Saddle Point Critical point包括Local Minima与Saddle Point。
当有很多参数时，Local Minima几乎不存在。
2.2 Batch与Momentum Batch Shuffle：在一个epoch结束后重新分batch。 大Batch v.s. 小Batch
当考虑并行运算（gpu）后，大Batch的运行速度更快。
小Batch的noise更大，但这反而有助于训练。</p></div><div class=card-footer><span class=float-left>October 17, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-2/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-3/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-3</h5><p class="card-text post-summary">李宏毅-机器学习2021春-3 1 Classification 将Class用one-hot vector表示
回归与分类的区别：
softmax：
Loss的计算：
2 Convolutional Neural Network (CNN) 为Image Classification设计的网络。
默认Image大小为100*100。
Receptive field（感受野）：图像的一个局部特征 共享参数：w1，w2是相同的 receptive field + sharing parameteres = convolutional layer
Convolutional layer：由一堆Filter组成，Filter捕捉图片里的pattern。 Feature Map：图片经过Convolution layer得到的结果 Pooling—Max Pooling
没有参数需要学习
Spatial Transformer Layer：解决CNN无法面对放大和旋转的问题
3 Self-attention 3.1 背景 当输入是多组向量时，输出的情况：
每一个向量都有一个label（sequence labeling），此处可以用self-attention 整个sequence有一个label 模型自己决定输出长度（seq to seq） 3.2 原理 Self-attention的输出$b^1$，既代表$a^1$，又代表$a^1$和$a^2$、$a^3$的关系。</p></div><div class=card-footer><span class=float-left>October 17, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-3/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-4/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-4</h5><p class="card-text post-summary">李宏毅-机器学习2021春-4 1 Transformer Sequence-to-sequence（Seq2seq）
输出的长度由模型决定 Encoder+Decoder 1.1 Encoder encoder内部由许多block组成：
每个block的构成如下：
1.2 Decoder-Autoregressive(AT) 与Encoder的对比图：（Multi-Head Attention前加了一个Masked）
Masked Self-attention 产生$b^1$的时候只能考虑$b^1$的资讯。 产生$b^2$的时候只能考虑$b^1$、$b^2$的资讯。 产生$b^3$的时候只能考虑$b^1$、$b^2$、$b^3$的资讯。 1.3 Encoder-Decoder Cross attention:
Teacher Forcing: 用ground truth（答案）作为Decoder的输入
1.4 Training Tips Copy Mechanism Guided Attention Beam Search：不基于贪心的一种搜索算法 2 BERT Self-supervised Learning 系统通过输入数据的一部分进行predict，另一部分输入用于进行比对。
Masking Input Next Sentence Prediction 对于BERT不是很有用 BERT经过Fine-tune，可用于下游任务。
BERT整体是Semi-supervised的。填空题（Pre-train）阶段是Self-supervised，Finetune阶段是supervised。
2.1 Bert Case 用于语义分析。输出类别。BERT是用填空题预训练的。 用于词性标注。输出和输出长度相同。 用于自然语言推测。输入两个句子，输出一个类别。 基于提取的问答系统 输入一个问题和一篇文档，输出答案的起始位置和结束位置。 2.</p></div><div class=card-footer><span class=float-left>October 17, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-4/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-5/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-5</h5><p class="card-text post-summary">李宏毅-机器学习2021春-5 1 Word Embedding 将每一个Word都投影到一个High Dimension的空间上。 相似的词距离近。 不同的Dimension代表不同的含义。 Word Embedding是一个unsupervised的过程。机器通过阅读大量文章，根据上下文信息进行学习。
Counting based
Prediction based：拿出Prediction Model的第一个hiden layer，即可得到word embedding.
2 Recurrent Neural Network ​ 有记忆的NN。
Long Shor-term Memory(LSTM)</p></div><div class=card-footer><span class=float-left>October 17, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-5/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-1/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-1</h5><p class="card-text post-summary">李宏毅-机器学习2021春-1 1 机器学习基本概念 1.1 机器学习基本任务 机器学习的基本任务：寻找一个函数
不同种类的函数：
Regression（回归）：函数输出一个标量 如：预测PM2.5 Clssificatiion（分类）：给定选项，函数输出选项 如：Alpha Go下棋 Structured Learning：创造一些结构（图片，文件） 1.2 通过训练数据定义Loss Loss 也是一个函数，它的输入是Model中的parameters： $$ L(b,w) $$
Loss function：$L=\frac{1}{N}\sum_ne_n$
Mean Absolute Error(MAE)：$e=|y-\hat{y}|$ Mean Square Error(MSE)：$e=(y-\hat{y})^2$ 1.3 Optimization 目标：得到最优的参数。 $$ w^{*}, b^{*}=\arg \min _{w, b} L $$ 方式：Gradient Descent
一个参数w的情况 随机选取初始值$w^0$ 计算$\left.\frac{\partial L}{\partial \mathcal{\imath}}\right|_{w=w^{0}}$ learning rate：$\eta$，表示梯度下降的速率 不断更新w：$w^{1} \leftarrow w^{0}-\left.\eta \frac{\partial L}{\partial w}\right|_{w=w^{0}}$ 两个参数的情况： 2 深度学习基本概念 2.</p></div><div class=card-footer><span class=float-left>October 15, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-1/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/algorithmdatastructure/%E7%BA%A2%E9%BB%91%E6%A0%91/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>红黑树</h5><p class="card-text post-summary">红黑树 性质 是一种特殊的**二叉查找树**（任意节点的左子树上的节点小于该节点，右子树上的节点大于该节点） 每个节点都是红色或黑色 每个叶子节点的子节点（NULL节点）为黑色 红色节点的子节点都是黑色 从一个结点到其所有的后代叶子结点的路径上包含的黑色结点数量相同。 性质5确保没有一条路径会比其他路径长出俩倍。因而，红黑树是相对是接近平衡的二叉树。
应用 主要是用它来存储有序的数据，它的时间复杂度是O(lgn)，效率非常之高。
例如：
Java集合中的TreeSet和TreeMap C++ STL中的set、map Linux虚拟内存的管理 基本操作 左旋&右旋 添加 将红黑树当作一颗二叉查找树，将节点插入，着色为红色。
由于可能违背了性质4，故需要调整。分三种情况：
叔叔是红色
叔叔是黑色，且当前节点是右孩子
叔叔是黑色，且当前节点是左孩子
删除</p></div><div class=card-footer><span class=float-left>September 22, 2021</span>
<a href=/posts/algorithmdatastructure/%E7%BA%A2%E9%BB%91%E6%A0%91/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-2/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>知识梳理 2</h5><p class="card-text post-summary">知识梳理 2 4 CPU调度 基本概念 CPU调度：在主存中选择运行实体（ready queue中的进程/线程），并将CPU分配给它。在内核状态下选择、分配、激活。
进程执行周期：CPU burst + I/O burst CPU burst：进程在 running state I/O burst：进程在 waiting state 进程调度需要以下两个部件： 短期调度程序（short-term scheduler） 分派程序（dispatcher）：将CPU分配给短期调度程序选择的进程，功能包括 进程上下文切换 转到user mode 跳到用户程序的合适位置重新开始执行 上图中的t0-t3为派遣时延（dispatch latency）
调度什么时候出现：（1,2为非抢占式，3,4为抢占式）
进程终止 运行的进程转为waiting状态（e.g., 进程主动I/O requests，或调用wait等待子进程终止） 运行的进程转为ready状态（e.g.，中断出现，或时间戳结束） waiting->ready（e.g.，I/O完成） 调度准则 调度算法</p></div><div class=card-footer><span class=float-left>September 3, 2021</span>
<a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-2/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/linux/part-1/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Part 1</h5><p class="card-text post-summary">Part 1 1 Linux终端与主机 Ctrl-A的ASCII码是1，Ctrl-B的ASCII码是2，Ctrl-C的ASCII码是3，。。。，Ctrl-Z的ASCII码是26
Esc的ASCII码是27
行律功能调整：stty
查看：stty -a stty erase ^H 流控方式：
硬件方式：RS232接口的CTS信号（Clear To Send）（不好） 软件方式：利用流控字符Xon（Ctrl-S, 17）和Xoff（Ctrl-Q，19） 2 系统状态查看 2.1 用户登录 Linux用户分为：
root用户（超级用户） 普通用户 创建新用户：
由root用户创建（useradd命令），用户信息存放在/etc/passwd文件中，包括用户名和用户ID，以及Home目录，登录shell 登录shell：一般为bash，也可以选其它shell，甚至自己设计的程序。 登录后的shell提示符：
$：Bourne Shell系列（sh，ksh，bash） #：当前用户为超级用户root 2.2 查看手册、时间、计算器、口令维护 Linux命令大小写敏感。
几种常用的系统命令：
man：查看系统常用手册
date：读取系统日期和时间
cal：日历
cal 10 2019 cal 2019 bc：计算器</p></div><div class=card-footer><span class=float-left>September 2, 2021</span>
<a href=/posts/linux/part-1/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/linux/part-2/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Part 2</h5><p class="card-text post-summary">Part 2 1 正则表达式 1.1 基础 正则表达式与文件匹配符规则不同。
六个元字符：. * $ ^ [ \
. 代表任意字符 x* 代表任意多个x（0-n个） 123$ 代表匹配文件行尾的123 ^123 代表匹配每行起始的123 []用于定义区间 \1 \2代表前面的第一部分和第二部分 定义集和
ERE、PCRE：扩展的正则表达式 1.2 跟正则表达式相关的命令 grep/egrep/fgrep
语法：grep 模式 文件名列表 egrep：用扩展正则表达式搜索 fgrep：快速搜索字符串，不用正则表达式规则 sed：流编辑
awk：逐行扫描进行文本处理的一门语言</p></div><div class=card-footer><span class=float-left>September 2, 2021</span>
<a href=/posts/linux/part-2/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/sdn/sdn-1/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>SDN 1</h5><p class="card-text post-summary">SDN 1 1 SDN概述 1.1 SDN之前的网络架构 1.2 SDN定义 网络控制和转发功能解耦合，使得网络控制功能可直接编程。 Openflow协议是SDN方案的基础。 SDN的开放分层架构加速了网络产业的参与度，越来越多的网络用户、网络软件公司参与到参与中。 1.3 SDN的分层体系结构</p></div><div class=card-footer><span class=float-left>September 2, 2021</span>
<a href=/posts/sdn/sdn-1/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-1/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>知识梳理 1</h5><p class="card-text post-summary">知识梳理 1 1 Introduction 计算机启动过程 BIOS -> MBR -> boot loader -> kernel -> init process
当我们打开计算机电源，计算机会自动从主板的BIOS(Basic Input/Output System)读取其中所存储的程序。这一程序通常知道一些直接连接在主板上的硬件(硬盘，网络接口，键盘，串口，并口)。现在大部分的BIOS允许你从软盘、光盘或者硬盘中选择一个来启动计算机。 下一步，计算机将从你所选择的存储设备中读取起始的512 bytes。这512 bytes叫做主引导记录MBR (master boot record)。MBR会告诉电脑从该设备的某一个分区(partition)来装载引导加载程序(boot loader)。Boot loader储存有操作系统(OS)的相关信息，比如操作系统名称，操作系统内核 (kernel)所在位置等。 随后，boot loader将kernel加载到内存中。kernel实际上是一个用来操作计算机的程序，它是计算机操作系统的内核，主要的任务是管理计算机的硬件资源，充当软件和硬件的接口。操作系统上的任何操作都要通过kernel传达给硬件。Windows和Linux各自有自己kernel。狭义的操作系统就是指kernel，广义的操作系统包括kernel以及kernel之上的各种应用。 kernel开始加载第一个进程，例如"init"，并等待事件的出现。 事件 中断（interrupt/trap）：由硬件或外设触发，通过系统总线发一个信号给CPU，一般为异步方式。 中断会有一个中断ID。 程序会保存中断发生前一时刻的执行现场（保存一些寄存器中的值），然后去转到中断的服务例程执行中断。 中断完毕后，OS再恢复之前保存的处理状态，故中断是对应用程序透明的。 如：read系统调用后，系统发出读磁盘的操作，当磁盘数据准备好后，向OS发出一个异步通知消息。 异常（exception）：由应用程序触发，一般为同步方式。 异常也有异常编号ID，也会保存现场。 如：除0异常，无效地址访问 系统调用（system call）：由应用程序触发，应用程序向OS请求某个服务，异步或同步。 大多由应用程序通过API调用，而非直接由系统调用 存储结构 I/O 结构 每个设备控制器控制一种设备，负责控制数据在它自己的本地缓存和外部设备中的移动。 OS 为每个设备控制器分配了一个设备驱动器。 DMA（Direct Memory Access）——用于大块数据的移动</p></div><div class=card-footer><span class=float-left>September 2, 2021</span>
<a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-1/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div></div><div class=paginator><ul class=pagination><li class=page-item><a href=/posts/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class="page-item disabled"><a class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class="page-item active"><a class=page-link href=/posts/>1</a></li><li class=page-item><a class=page-link href=/posts/page/2/>2</a></li><li class=page-item><a class=page-link href=/posts/page/3/>3</a></li><li class=page-item><a href=/posts/page/2/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/posts/page/3/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=/#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=/#recent-posts>Recent Posts</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><span>Email:</span> <span>2018211947@bupt.edu.cn</span></li></ul></div><div class="col-md-4 col-sm-12"><p>Stay up to date with email notification</p><form><div class=form-group><input type=email class=form-control id=exampleInputEmail1 aria-describedby=emailHelp placeholder="Enter email">
<small id=emailHelp class="form-text text-muted">By entering your email address, you agree to receive the newsletter of this website.</small></div><button type=submit class="btn btn-info">Submit</button></form></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2022 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script src=/js/list.js></script></body></html>