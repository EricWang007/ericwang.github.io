<!doctype html><html><head><title>Posts</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css><meta property="og:title" content="Posts"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://ericwang007.github.io/posts/"><meta property="og:updated_time" content="2021-10-17T06:00:20+06:00"><link rel=stylesheet href=/css/layouts/list.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/>EricWang's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"></ul></div></div></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts data-filter=all>Posts</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/posts/algorithmdatastructure/>Algorithm&DataStructure</a><ul><li><a href=/posts/algorithmdatastructure/%E6%8E%92%E5%BA%8F%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/ title=排序方法总结>排序方法总结</a></li><li><a href=/posts/algorithmdatastructure/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91/ title=最小生成树>最小生成树</a></li><li><a href=/posts/algorithmdatastructure/%E7%BA%A2%E9%BB%91%E6%A0%91/ title=红黑树>红黑树</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/bigdata/>BigData</a><ul><li><a href=/posts/bigdata/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%84%E4%BB%B6/ title=大数据组件>大数据组件</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/database/>Database</a><ul><li><a href=/posts/database/1-introduction/ title="1 Introduction">1 Introduction</a></li><li><a href=/posts/database/2-relation-database/ title="Relation Database">Relation Database</a></li><li><a href=/posts/database/3-sql/ title=SQL>SQL</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/java/>Java</a><ul><li><a href=/posts/java/java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/ title=Java基础语法>Java基础语法</a></li><li><a href=/posts/java/java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/ title=Java集合框架>Java集合框架</a></li><li><a href=/posts/java/java%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98/ title=Java面试问题>Java面试问题</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/ml/>ML</a><ul><li><a href=/posts/ml/andrewng-cv%E5%9F%BA%E7%A1%80/ title=AndrewNG-CV基础>AndrewNG-CV基础</a></li><li><a href=/posts/ml/andrewng-dl%E5%9F%BA%E7%A1%80/ title=AndrewNG-DL基础>AndrewNG-DL基础</a></li><li><a href=/posts/ml/andrewng-dl%E5%BA%94%E7%94%A8/ title=AndrewNG-DL应用>AndrewNG-DL应用</a></li><li><a href=/posts/ml/andrewng-gan%E5%9F%BA%E7%A1%80/ title=AndrewNG-GAN基础>AndrewNG-GAN基础</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-1/ title=李宏毅-机器学习2021春-1>李宏毅-机器学习2021春-1</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-2/ title=李宏毅-机器学习2021春-2>李宏毅-机器学习2021春-2</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-3/ title=李宏毅-机器学习2021春-3>李宏毅-机器学习2021春-3</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-4/ title=李宏毅-机器学习2021春-4>李宏毅-机器学习2021春-4</a></li><li><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-5/ title=李宏毅-机器学习2021春-5>李宏毅-机器学习2021春-5</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/os/>OS</a><ul><li><a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-1/ title="知识梳理 1">知识梳理 1</a></li><li><a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-2/ title="知识梳理 2">知识梳理 2</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid post-card-holder" id=post-card-holder><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-2/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-2</h5><p class="card-text post-summary">李宏毅-机器学习2021春-2 1 机器学习任务攻略 Model bias：模型过于简单，有局限性
Optimization Issue：模型足够复杂了，但Optimization做的不够好。
Overfitting：在训练集上效果好，在测试集上效果差。解决方法如下：
增加训练数据，Data augmentation（图片左右翻转） 限制模型，减少模型的flexibility： 减少参数，共享参数（CNN） 减少features Early stopping Regularization Dropout 模型的复杂性需要在Overfitting和Model bias间进行trade-off
mismatch：训练集和测试集的数据分别不同
N-fold Cross Validation：将Training Set进行不同的分组，分别对模型进行训练和验证，得到的mse取平均值。
2 类神经网络训练不起来怎么办 2.1 Local Minima与Saddle Point Critical point包括Local Minima与Saddle Point。
当有很多参数时，Local Minima几乎不存在。
2.2 Batch与Momentum Batch Shuffle：在一个epoch结束后重新分batch。 大Batch v.s. 小Batch
当考虑并行运算（gpu）后，大Batch的运行速度更快。
小Batch的noise更大，但这反而有助于训练。</p></div><div class=card-footer><span class=float-left>October 17, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-2/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-3/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-3</h5><p class="card-text post-summary">李宏毅-机器学习2021春-3 1 Classification 将Class用one-hot vector表示
回归与分类的区别：
softmax：
Loss的计算：
2 Convolutional Neural Network (CNN) 为Image Classification设计的网络。
默认Image大小为100*100。
Receptive field（感受野）：图像的一个局部特征 共享参数：w1，w2是相同的 recptive field + sharing parameteres = convolutional layer
Convolutional layer：由一堆Filter组成，Filter捕捉图片里的pattern。 Feature Map：图片经过Convolution layer得到的结果 Pooling—Max Pooling
没有参数需要学习
Spatial Transformer Layer：解决CNN无法面对放大和旋转的问题
3 Self-attention 3.1 背景 当输入是多组向量时，输出的情况：
每一个向量都有一个label（sequence labeling），此处可以用self-attention 整个sequence有一个label 模型自己决定输出长度（seq to seq） 3.2 原理 Self-attention的输出$b^1$，既代表$a^1$，又代表$a^1$和$a^2$、$a^3$的关系。</p></div><div class=card-footer><span class=float-left>October 17, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-3/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-4/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-4</h5><p class="card-text post-summary">李宏毅-机器学习2021春-4 1 Transformer Sequence-to-sequence（Seq2seq）
输出的长度由模型决定 Encoder+Decoder 1.1 Encoder encoder内部由许多block组成：
每个block的构成如下：
1.2 Decoder-Autoregressive(AT) 与Encoder的对比图：（Multi-Head Attention前加了一个Masked）
Masked Self-attention 产生$b^1$的时候只能考虑$b^1$的资讯。 产生$b^2$的时候只能考虑$b^1$、$b^2$的资讯。 产生$b^3$的时候只能考虑$b^1$、$b^2$、$b^3$的资讯。 1.3 Encoder-Decoder Cross attention:
Teacher Forcing: 用ground truth（答案）作为Decoder的输入
1.4 Training Tips Copy Mechanism Guided Attention Beam Search：不基于贪心的一种搜索算法 2 BERT Self-supervised Learning 系统通过输入数据的一部分进行predict，另一部分输入用于进行比对。
Masking Input Next Sentence Prediction 对于BERT不是很有用 BERT经过Fine-tune，可用于下游任务。
BERT整体是Semi-supervised的。填空题（Pre-train）阶段是Self-supervised，Finetune阶段是supervised。
2.1 Bert Case 用于语义分析。输出类别。BERT是用填空题预训练的。 用于词性标注。输出和输出长度相同。 用于自然语言推测。输入两个句子，输出一个类别。 基于提取的问答系统 输入一个问题和一篇文档，输出答案的起始位置和结束位置。 2.</p></div><div class=card-footer><span class=float-left>October 17, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-4/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-5/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-5</h5><p class="card-text post-summary">李宏毅-机器学习2021春-5 1 Word Embedding 将每一个Word都投影到一个High Dimension的空间上。 相似的词距离近。 不同的Dimension代表不同的含义。 Word Embedding是一个unsupervised的过程。机器通过阅读大量文章，根据上下文信息进行学习。
Counting based
Prediction based：拿出Prediction Model的第一个hiden layer，即可得到word embedding.
2 Recurrent Neural Network ​ 有记忆的NN。
Long Shor-term Mem4ory(LSTM)</p></div><div class=card-footer><span class=float-left>October 17, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-5/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-1/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>李宏毅-机器学习2021春-1</h5><p class="card-text post-summary">李宏毅-机器学习2021春-1 1 机器学习基本概念 1.1 机器学习基本任务 机器学习的基本任务：寻找一个函数
不同种类的函数：
Regression（回归）：函数输出一个标量 如：预测PM2.5 Clssificatiion（分类）：给定选项，函数输出选项 如：Alpha Go下棋 Structured Learning：创造一些结构（图片，文件） 1.2 通过训练数据定义Loss Loss 也是一个函数，它的输入是Model中的parameters： $$ L(b,w) $$
Loss function：$L=\frac{1}{N}\sum_ne_n$
Mean Absolute Error(MAE)：$e=|y-\hat{y}|$ Mean Square Error(MSE)：$e=(y-\hat{y})^2$ 1.3 Optimization 目标：得到最优的参数。 $$ w^{*}, b^{*}=\arg \min _{w, b} L $$ 方式：Gradient Descent
一个参数w的情况 随机选取初始值$w^0$ 计算$\left.\frac{\partial L}{\partial \mathcal{\imath}}\right|_{w=w^{0}}$ learning rate：$\eta$，表示梯度下降的速率 不断更新w：$w^{1} \leftarrow w^{0}-\left.\eta \frac{\partial L}{\partial w}\right|_{w=w^{0}}$ 两个参数的情况： 2 深度学习基本概念 2.</p></div><div class=card-footer><span class=float-left>October 15, 2021</span>
<a href=/posts/ml/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021%E6%98%A5-1/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/algorithmdatastructure/%E7%BA%A2%E9%BB%91%E6%A0%91/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>红黑树</h5><p class="card-text post-summary">红黑树 性质 是一种特殊的**二叉查找树**（任意节点的左子树上的节点小于该节点，右子树上的节点大于该节点） 每个节点都是红色或黑色 每个叶子节点的子节点（NULL节点）为黑色 红色节点的子节点都是黑色 从一个结点到其所有的后代叶子结点的路径上包含的黑色结点数量相同。 性质5确保没有一条路径会比其他路径长出俩倍。因而，红黑树是相对是接近平衡的二叉树。
应用 主要是用它来存储有序的数据，它的时间复杂度是O(lgn)，效率非常之高。
例如：
Java集合中的TreeSet和TreeMap C++ STL中的set、map Linux虚拟内存的管理 基本操作 左旋&右旋 添加 将红黑树当作一颗二叉查找树，将节点插入，着色为红色。
由于可能违背了性质4，故需要调整。分三种情况：
叔叔是红色
叔叔是黑色，且当前节点是右孩子
叔叔是黑色，且当前节点是左孩子
删除</p></div><div class=card-footer><span class=float-left>September 22, 2021</span>
<a href=/posts/algorithmdatastructure/%E7%BA%A2%E9%BB%91%E6%A0%91/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-2/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>知识梳理 2</h5><p class="card-text post-summary">知识梳理 2 4 CPU调度 基本概念 CPU调度：在主存中选择运行实体（ready queue中的进程/线程），并将CPU分配给它。在内核状态下选择、分配、激活。
进程执行周期：CPU burst + I/O burst CPU burst：进程在 running state I/O burst：进程在 waiting state 进程调度需要以下两个部件： 短期调度程序（short-term scheduler） 分派程序（dispatcher）：将CPU分配给短期调度程序选择的进程，功能包括 进程上下文切换 转到user mode 跳到用户程序的合适位置重新开始执行 上图中的t0-t3为派遣时延（dispatch latency）
调度什么时候出现：（1,2为非抢占式，3,4为抢占式）
进程终止 运行的进程转为waiting状态（e.g., 进程主动I/O requests，或调用wait等待子进程终止） 运行的进程转为ready状态（e.g.，中断出现，或时间戳结束） waiting->ready（e.g.，I/O完成） 调度准则 调度算法</p></div><div class=card-footer><span class=float-left>September 3, 2021</span>
<a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-2/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-1/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>知识梳理 1</h5><p class="card-text post-summary">知识梳理 1 1 Introduction 计算机启动过程 BIOS -> MBR -> boot loader -> kernel -> init process
当我们打开计算机电源，计算机会自动从主板的BIOS(Basic Input/Output System)读取其中所存储的程序。这一程序通常知道一些直接连接在主板上的硬件(硬盘，网络接口，键盘，串口，并口)。现在大部分的BIOS允许你从软盘、光盘或者硬盘中选择一个来启动计算机。 下一步，计算机将从你所选择的存储设备中读取起始的512 bytes。这512 bytes叫做主引导记录MBR (master boot record)。MBR会告诉电脑从该设备的某一个分区(partition)来装载引导加载程序(boot loader)。Boot loader储存有操作系统(OS)的相关信息，比如操作系统名称，操作系统内核 (kernel)所在位置等。 随后，boot loader将kernel加载到内存中。kernel实际上是一个用来操作计算机的程序，它是计算机操作系统的内核，主要的任务是管理计算机的硬件资源，充当软件和硬件的接口。操作系统上的任何操作都要通过kernel传达给硬件。Windows和Linux各自有自己kernel。狭义的操作系统就是指kernel，广义的操作系统包括kernel以及kernel之上的各种应用。 kernel开始加载第一个进程，例如"init"，并等待事件的出现。 事件 中断（interrupt/trap）：由硬件或外设触发，通过系统总线发一个信号给CPU，一般为异步方式。 中断会有一个中断ID。 程序会保存中断发生前一时刻的执行现场（保存一些寄存器中的值），然后去转到中断的服务例程执行中断。 中断完毕后，OS再恢复之前保存的处理状态，故中断是对应用程序透明的。 如：read系统调用后，系统发出读磁盘的操作，当磁盘数据准备好后，向OS发出一个异步通知消息。 异常（exception）：由应用程序触发，一般为同步方式。 异常也有异常编号ID，也会保存现场。 如：除0异常，无效地址访问 系统调用（system call）：由应用程序触发，应用程序向OS请求某个服务，异步或同步。 大多由应用程序通过API调用，而非直接由系统调用 存储结构 I/O 结构 每个设备控制器控制一种设备，负责控制数据在它自己的本地缓存和外部设备中的移动。 OS 为每个设备控制器分配了一个设备驱动器。 DMA（Direct Memory Access）——用于大块数据的移动</p></div><div class=card-footer><span class=float-left>September 2, 2021</span>
<a href=/posts/os/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-1/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/database/1-introduction/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>1 Introduction</h5><p class="card-text post-summary">1 Introduction DBMS & DBS
DBS：数据库系统 包括：DBMS、数据库、数据库应用程序、数据库管理人员 DBMS：数据库管理系统 对数据的管理包括：定义信息的存储格式、提供操作信息的方法 三级模式结构
内模式（物理层）：数据如何存储、第层数据结构 逻辑模式（逻辑层）：描述数据库中存的是什么数据，以及这些数据之间的关系，数据库管理人员运用逻辑层的抽象。是一个全局逻辑结构。 外模式（视图层）：数据库用户能够看到的和使用的局部数据的逻辑结构。系统可以为同一个数据库提供多个视图。 逻辑数据独立性：当概念模式变化时，可以不改变外部模式和应用程序。
物理数据独立性：当内部模式变化时，可以不改变概念模式和外部模式。
Instance（实例）：某一时刻，数据库中存储的数据集合
Schema（模式）：数据库系统的总体设计
Data-Definition Language (DDL)：create、alter、drop
Data-Manipulation Language (DML)：如SQL中的insert、delete from、update</p></div><div class=card-footer><span class=float-left>August 30, 2021</span>
<a href=/posts/database/1-introduction/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/database/2-relation-database/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Relation Database</h5><p class="card-text post-summary">2 Relation Database 关系模式
关系实例
super key：一个或多个属性的集合，这些属性的组合可以使我们在一个关系中唯一地标识一个元组。
candidate key：最小的super key
primary key：被设计者选中的 candidate key
**foreign key: ** 一个关系模式（r1）在它的属性中包括另一个关系模式（r2）的 primary key，则这个属性在r1上称作参照r2的 foreign key.
r1称作 foreign key 依赖的参照关系（referencing relation），r2称作 foreign key 的被参照关系(referenced relation)。 **参照完整性约束(referential integrity constraint): **在参照关系中任意元组在特定属性上的取值必然等于被参照关系在特定属性上的取值。</p></div><div class=card-footer><span class=float-left>August 30, 2021</span>
<a href=/posts/database/2-relation-database/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/database/3-sql/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>SQL</h5><p class="card-text post-summary">3 SQL Data Definition create table create table instructor( ID char(5), name varchar(20) not null, dept_name varchar(20), salary numeric(8,2), primary key(ID), foreign key(dept_name) references department, check(salary>0); ) insert insert into instructor values(080040, 'Jack', 'Com.Sci', 8000) delete delete from isntructor drop drop table r alter table alter table r add A D alter table r drop A Select Query select distinct dept_name from instructor # 去重 select all dept_name from instructor # 不去重 select T.</p></div><div class=card-footer><span class=float-left>August 30, 2021</span>
<a href=/posts/database/3-sql/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=/posts/bigdata/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%84%E4%BB%B6/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>大数据组件</h5><p class="card-text post-summary">大数据组件 Google的“三驾马车”：
Google File System (GFS) 适用于大规模分布式数据处理的、可扩展的分布式文件系统 MapReduce 一种用于大规模分布式数据的计算框架 BigTable –一种构建在GFS之上的分布式数据库系统 1 Hadoop Hadoop是Apache软件基金会旗下的一个开源的大数据处理框架。
Hadoop基础架构 –NameNode：负责管理HDFS的元数据信息
–Secondary NameNode：协助NameNode管理HDFS元数据信息
–DataNode：负责实际数据的存储
–JobTracker：负责MapReduce作业管理、资源调度等
–TaskTrack：负责Map以及Reduce任务的执行和任务状态的回报
Hadoop生态系统 2 HDFS Hadoop Distributed File System 与MaReduce同为Hadoop的核心组件 块级别的分布式文件系统 3 HBase HBase是谷歌BigTable的开源实现，因此，具有与 BigTable类似的特性 采用HDFS作为底层存储 依赖Zookeeper提供的分布式协调服务 与传统关系型数据库的区别：
数据类型：关系数据库采用关系模型，具有丰富的数据类型和存储方式；HBase则采用了更加简单的数据模型， 它把数据存储为未经解释的字符串。 数据操作：只有简单的插入、查询、删除、清空。 存储模式：基于列存储，每个列族都由几个文件保存，不同列族的文件是分离的。 数据索引：HBase只有一个索引——行键，HBase中的所有访问方法，或者通过行键访问，或 者通过行键扫描。 数据维护：在HBase中执行更新操作时，并不会删除数据旧的版本，而 是生成一个新的版本，旧的版本仍然保留。 HBase系统架构 HMaster HMaster可以存在多个，主HMaster由ZooKeeper动态选举 产生 协调RegionServer 管理元信息 ZooKeeper 内部存储着有关HBase的重要元信息和状态信息，担任HMaster与RegionServer之间的服务协调角色 RegionServer 负责Region的存储和管理并与Client交互 处理读写请求 Client Client提供HBase访问接口 与RegionServer交互读写数 据，并维护cache加快对HBase的访问速度。 4 Kafka 为了降低数据生产者和消费者之间的耦合度而引入的一层“中间件”。</p></div><div class=card-footer><span class=float-left>August 30, 2021</span>
<a href=/posts/bigdata/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%84%E4%BB%B6/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div></div><div class=paginator><ul class=pagination><li class=page-item><a href=/posts/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class="page-item disabled"><a class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class="page-item active"><a class=page-link href=/posts/>1</a></li><li class=page-item><a class=page-link href=/posts/page/2/>2</a></li><li class=page-item><a href=/posts/page/2/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/posts/page/2/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=/#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=/#recent-posts>Recent Posts</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><span>Email:</span> <span>2018211947@bupt.edu.cn</span></li></ul></div><div class="col-md-4 col-sm-12"><p>Stay up to date with email notification</p><form><div class=form-group><input type=email class=form-control id=exampleInputEmail1 aria-describedby=emailHelp placeholder="Enter email">
<small id=emailHelp class="form-text text-muted">By entering your email address, you agree to receive the newsletter of this website.</small></div><button type=submit class="btn btn-info">Submit</button></form></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2022 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script src=/js/list.js></script></body></html>